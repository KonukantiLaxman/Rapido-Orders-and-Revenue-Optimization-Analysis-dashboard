#!/usr/bin/env python
# coding: utf-8

# In[108]:


#importing required libraries 
import pandas as pd 
import numpy as np


# In[109]:


#loading dataset 
df=pd.read_csv("rapido_single_master_dataset_3000_dirty.csv")
df


# In[110]:


#for top 5 records 
df.head()


# In[111]:


#for bottom 5 records 
df.tail()


# In[112]:


#undertanding the dataset 
df.info()


# In[113]:


#statistical measures 
df.describe()


# In[114]:


#Checking for datatypes 
df.dtypes


# In[115]:


# categorical columns
category = ['month','slot','app_opened','ride_booked','app_label','status','vehicle','weather']
df[category] = df[category].astype('category')
# date columns
df['ride_date'] = pd.to_datetime(df['ride_date'], errors='coerce')
# derive year properly
df['year'] = df['ride_date'].dt.year.astype('Int64')
# time column (keep only time)
df['time'] = pd.to_datetime(df['time'], errors='coerce')
# datetime columns
df['login']  = pd.to_datetime(df['login'], errors='coerce')
df['logout'] = pd.to_datetime(df['logout'], errors='coerce')


# In[116]:


#rechecking for datatypes 
df.dtypes


# In[117]:


#checking for duplicates 
df.duplicated().sum()


# In[118]:


#fixing/ droping duplicates 
df.drop_duplicates(inplace=True)


# In[119]:


#rechecking for duplicates 
df.duplicated().sum()


# In[120]:


#checking for invalid values 
df.select_dtypes(include='number')\
.where(df.select_dtypes(include='number')<0)\
.stack()


# In[121]:


#fixing invalid values 
num=df.select_dtypes(include='number').columns
df[num]=df[num].where(df.select_dtypes(include='number')>0,np.nan)


# In[122]:


#checking for invalid values 
df.select_dtypes(include='number')\
.where(df.select_dtypes(include='number')<0)\
.stack()


# In[123]:


#checking for skew 
df.select_dtypes(include='number').skew()


# In[124]:


#fixing skew and null values 
median=['km','price','platform','captain','hrs']
df[median]=df[median].fillna(df[median].median())


# In[125]:


#checkking for outliers 
#checking for skew 
df.select_dtypes(include='number').boxplot()


# In[126]:


#checking for null  values 
df.isnull().sum()


# In[127]:


df.dtypes


# In[128]:


#numerical data nan filling with mean
num=df.select_dtypes(include='number').columns
df[num]=df[num].fillna(df[num].mean())
#category filling with mode 
category=df.select_dtypes(include='category').columns 
df[category]=df[category].fillna(df[category].mode().iloc[0])


# In[129]:


df.isnull().sum()


# In[130]:


df['ride_date'] = pd.to_datetime(df['ride_date'], errors='coerce')

ride_date_mode = df['ride_date'].mode()[0]
df['ride_date'].fillna(ride_date_mode, inplace=True)


# In[131]:


df['year'] = df['ride_date'].dt.year.astype('Int64')


# In[132]:


df['time'] = df['time'].fillna(df['time'].median())


# In[133]:


df['login'] =df['login'].median()


# In[134]:


df['logout']=df['logout'].median()


# In[135]:


df.isnull().sum()


# In[136]:


df.to_csv("rapido_cleaned_final.csv", index=False)


# In[137]:


import seaborn as sns
import matplotlib.pyplot as plt 


# In[146]:


# Orders by time slot
sns.countplot(x='slot', data=df)
plt.show()


# In[147]:


# Price vs Weather
sns.boxplot(x='weather', y='price', data=df)
plt.show()


# In[153]:


df.groupby('slot')['ride_id'].count()


# In[150]:


df[['price','km','hrs']].describe()


# In[152]:


df.groupby('vehicle')['price'].mean()


# In[155]:


df.groupby('slot')['price'].mean()


# In[156]:


df.groupby('weather')['price'].mean()


# In[ ]:




